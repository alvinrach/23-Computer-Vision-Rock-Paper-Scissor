{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "23-Computer Vision-Rock Paper Scissor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjSaga/RWjuUk7OwN6oEGY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinrach/23-Computer-Vision-Rock-Paper-Scissor/blob/main/23_Computer_Vision_Rock_Paper_Scissor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEShcKk1aU-b"
      },
      "source": [
        "# Mohon menggunakan GPU yang disediakan Colab (Runtime > Change Runtime Type > GPU > Save)\n",
        "\n",
        "**Nama: Alvin Rachmat**\n",
        "\n",
        "**Project: Computer Vison - Mendeteksi suit batu, gunting, atau kertas**\n",
        "\n",
        "**Indosat Ooredoo x Dicoding Machine Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHp626SiCU_Y"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9umz_eKuxx9D",
        "outputId": "fc5d70d4-ac0f-423b-a2ee-6bfdd419c5b6"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-23 16:13:45--  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip\n",
            "Resolving dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)... 52.239.197.36\n",
            "Connecting to dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)|52.239.197.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/zip]\n",
            "Saving to: ‘/tmp/rockpaperscissors.zip’\n",
            "\n",
            "/tmp/rockpapersciss 100%[===================>] 307.92M  9.17MB/s    in 38s     \n",
            "\n",
            "2021-05-23 16:14:24 (8.02 MB/s) - ‘/tmp/rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C8A_1305BI1"
      },
      "source": [
        "import zipfile, os\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LYfVj73CzMf",
        "outputId": "fae0c87e-5a25-4802-ac6c-66baa5dd5b02"
      },
      "source": [
        "dir='/tmp/rockpaperscissors/rps-cv-images'\n",
        "\n",
        "datagen=ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "\n",
        "                    # Merotasi gambar dalam rentang 40 derajat\n",
        "                    rotation_range=40,\n",
        "\n",
        "                    # Flipping gambar\n",
        "                    horizontal_flip=True,\n",
        "                    vertical_flip=True, #Tidak diajarkan di kelas dicoding\n",
        "\n",
        "                    # Menggeser-geser gambar\n",
        "                    width_shift_range=0.3, #Tidak diajarkan di kelas dicoding\n",
        "                    height_shift_range=0.3, #Tidak diajarkan di kelas dicoding\n",
        "\n",
        "                    # Shear transformation (skewing) gambar\n",
        "                    shear_range = 0.2,\n",
        "\n",
        "                    # Rentang zoom 0.8-1.2x\n",
        "                    zoom_range=0.2,\n",
        "                    \n",
        "                    # Kecerahan\n",
        "                    brightness_range=[0.9,1.0], #Tidak diajarkan di kelas dicoding\n",
        "\n",
        "                    # Metode filling warna untuk mengisi bagian yang kosong setelah digeser/rotasi/etc\n",
        "                    fill_mode = 'nearest',\n",
        "                    \n",
        "                    #Membagi gambar menjadi 40% untuk data validasi, sisanya training\n",
        "                    validation_split=0.4\n",
        "                    )\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        dir,  # Direktori foto\n",
        "        target_size=(100, 150),  # Resolusi input 200 x 300 merujuk pada readme notes\n",
        "        batch_size=1,\n",
        "        class_mode='categorical', # Klasifikasi tiga kelas sehingga kategorinya adalah categorical\n",
        "        subset='training'\n",
        "        )\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "        dir, # Direktori foto\n",
        "        target_size=(100, 150), # Resolusi input 200 x 300 merujuk pada readme notes\n",
        "        batch_size=1,\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "        )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1314 images belonging to 3 classes.\n",
            "Found 874 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeYXepEf1FBb"
      },
      "source": [
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "    tf.keras.Input((100,150,3)), # Tidak diajarkan di kelas dicoding. Style input berbeda yang hasil akhirnya sama\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'), # Menggunakan lebih banyak hidden layer\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'), # Selain itu filternya juga ditingkatkan dengan pola yang berbeda dari kelas dicoding\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'), # Peningkatannya berpangkat dua untuk memaksimalkan kinerja GPU dalam satu kali layer\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'), # Umumnya CNN menggunakan dua layer FC (Fully Connected) saja \n",
        "    tf.keras.layers.Dense(3, activation='softmax') # Output layer ada 3 sehingga menggunakan softmax function\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp6P56z61abj"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', # Tidak diajarkan di kelas dicoding \n",
        "              # (Yang dipakai di dicoding adalah sparse_categorical_entropy pada latihan data Mnist)\n",
        "\n",
        "              optimizer='sgd', # Kelebihan Adam adalah cepat namun cukup baik, sedangkan SGD lambat namun menggeneralisasi lebih baik\n",
        "              # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "              \n",
        "              metrics=['accuracy']\n",
        "              )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4vr-wqm1cgi",
        "outputId": "9056edb5-1167-43e3-9c44-eb091e1d1c84"
      },
      "source": [
        "# Memanggil kembali epoch dengan performa terbaik setelah sejumlah 'patience' tertentu tiada peningkatan\n",
        "set_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15) # Tidak diajarkan di kelas dicoding\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs = 70,\n",
        "      validation_data=validation_generator,\n",
        "      callbacks=[set_callback],\n",
        "      verbose = 2\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "1314/1314 - 21s - loss: 1.0790 - accuracy: 0.3919 - val_loss: 0.9653 - val_accuracy: 0.6087\n",
            "Epoch 2/70\n",
            "1314/1314 - 15s - loss: 0.7833 - accuracy: 0.6385 - val_loss: 0.5748 - val_accuracy: 0.7220\n",
            "Epoch 3/70\n",
            "1314/1314 - 15s - loss: 0.5558 - accuracy: 0.7473 - val_loss: 0.4249 - val_accuracy: 0.8261\n",
            "Epoch 4/70\n",
            "1314/1314 - 15s - loss: 0.4544 - accuracy: 0.8044 - val_loss: 0.3379 - val_accuracy: 0.8810\n",
            "Epoch 5/70\n",
            "1314/1314 - 15s - loss: 0.4156 - accuracy: 0.8349 - val_loss: 0.5526 - val_accuracy: 0.7334\n",
            "Epoch 6/70\n",
            "1314/1314 - 14s - loss: 0.3553 - accuracy: 0.8645 - val_loss: 0.2624 - val_accuracy: 0.9245\n",
            "Epoch 7/70\n",
            "1314/1314 - 15s - loss: 0.2696 - accuracy: 0.9049 - val_loss: 1.6660 - val_accuracy: 0.6293\n",
            "Epoch 8/70\n",
            "1314/1314 - 14s - loss: 0.2134 - accuracy: 0.9346 - val_loss: 0.1203 - val_accuracy: 0.9588\n",
            "Epoch 9/70\n",
            "1314/1314 - 15s - loss: 0.2250 - accuracy: 0.9201 - val_loss: 0.2820 - val_accuracy: 0.8799\n",
            "Epoch 10/70\n",
            "1314/1314 - 15s - loss: 0.1856 - accuracy: 0.9361 - val_loss: 0.1675 - val_accuracy: 0.9508\n",
            "Epoch 11/70\n",
            "1314/1314 - 15s - loss: 0.1385 - accuracy: 0.9566 - val_loss: 0.0870 - val_accuracy: 0.9805\n",
            "Epoch 12/70\n",
            "1314/1314 - 15s - loss: 0.1779 - accuracy: 0.9452 - val_loss: 0.1688 - val_accuracy: 0.9531\n",
            "Epoch 13/70\n",
            "1314/1314 - 15s - loss: 0.1379 - accuracy: 0.9551 - val_loss: 0.0929 - val_accuracy: 0.9680\n",
            "Epoch 14/70\n",
            "1314/1314 - 15s - loss: 0.1290 - accuracy: 0.9513 - val_loss: 0.4377 - val_accuracy: 0.7597\n",
            "Epoch 15/70\n",
            "1314/1314 - 15s - loss: 0.1550 - accuracy: 0.9482 - val_loss: 0.1702 - val_accuracy: 0.9519\n",
            "Epoch 16/70\n",
            "1314/1314 - 15s - loss: 0.0990 - accuracy: 0.9703 - val_loss: 0.1119 - val_accuracy: 0.9577\n",
            "Epoch 17/70\n",
            "1314/1314 - 15s - loss: 0.0910 - accuracy: 0.9703 - val_loss: 0.0609 - val_accuracy: 0.9863\n",
            "Epoch 18/70\n",
            "1314/1314 - 15s - loss: 0.0837 - accuracy: 0.9718 - val_loss: 0.0857 - val_accuracy: 0.9817\n",
            "Epoch 19/70\n",
            "1314/1314 - 15s - loss: 0.1044 - accuracy: 0.9665 - val_loss: 0.0425 - val_accuracy: 0.9840\n",
            "Epoch 20/70\n",
            "1314/1314 - 15s - loss: 0.0425 - accuracy: 0.9878 - val_loss: 0.0511 - val_accuracy: 0.9817\n",
            "Epoch 21/70\n",
            "1314/1314 - 15s - loss: 0.0779 - accuracy: 0.9703 - val_loss: 0.0773 - val_accuracy: 0.9771\n",
            "Epoch 22/70\n",
            "1314/1314 - 15s - loss: 0.0599 - accuracy: 0.9833 - val_loss: 0.0747 - val_accuracy: 0.9805\n",
            "Epoch 23/70\n",
            "1314/1314 - 15s - loss: 0.0619 - accuracy: 0.9810 - val_loss: 0.0375 - val_accuracy: 0.9908\n",
            "Epoch 24/70\n",
            "1314/1314 - 15s - loss: 0.0704 - accuracy: 0.9810 - val_loss: 0.0332 - val_accuracy: 0.9920\n",
            "Epoch 25/70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeVNgw7Z1fUW"
      },
      "source": [
        "model.evaluate(validation_generator, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CDPKI8OLeAN"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "pd.DataFrame(history.history).plot(figsize=(9,6))\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Accuracy and Loss Graph')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HdHESVC1wn9"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "i=''\n",
        "\n",
        "while(i==''):\n",
        "  uploaded=files.upload()\n",
        "\n",
        "  for fn in uploaded.keys():\n",
        "    path = fn\n",
        "    img = image.load_img(path, target_size=(100,150))\n",
        "    imgplot = plt.imshow(img)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images, batch_size=10)\n",
        "    # Karena menggunakan categorical_crossentropy pada loss,\n",
        "    # terjemahkan hasilnya dengan argmax: me-return index yang memiliki nilai terbesar\n",
        "    j = np.argmax(classes)\n",
        "    \n",
        "    print(classes)\n",
        "    print(fn)\n",
        "\n",
        "    if j==0:\n",
        "      print('Paper')\n",
        "    elif j==1:\n",
        "      print('Rock')\n",
        "    elif j==2:\n",
        "      print('Scissor')\n",
        "\n",
        "  i=input('Again? [(yes: enter) / (no: ~enter)]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jj4FAgtr1BY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}